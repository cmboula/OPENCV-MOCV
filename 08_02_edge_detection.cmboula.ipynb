{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmboula/OPENCV-MOCV/blob/main/08_02_edge_detection.cmboula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvHPSqwx9o6i"
      },
      "source": [
        "<h1 style=\"font-size:30px;\">Edge Detection</h1>\n",
        "\n",
        "Edge detection is an image-processing technique used to identify the boundaries (edges) of objects, or regions within an image. Edges are among the most important features associated with images. We come to know of the underlying structure of an image through its edges. Computer vision processing pipelines therefore extensively use edge detection in applications. In this notebook, we will explore how convolution is used to detect edges and will cover the following edge detection methods.\n",
        "\n",
        "* Sobel Edge Detection\n",
        "* Canny Edge Detection\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://opencv.org/wp-content/uploads/2021/09/c0-m8-02-feature-image.png\" alt=\"c0-m8-02-feature-image.png\">\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Edge detection is applied to grayscale images that are also often blurred prior to performing edge detection. Blurring is performed to reduce the noise in the image. In edge detection, numerical derivatives of the pixel intensities are computed, and this typically results in ‘noisy’ edges. In other words, the intensity of neighboring pixels in an image (especially near edges) can fluctuate quite a bit, giving rise to edges that don’t represent the predominant edge structure we are typically looking for. Blurring smooths the intensity variation near the edges, making it easier to identify the edge structure within the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0lhz3nOD9WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de0162d-d06d-4169-c6ce-47f1b2626fe0"
      },
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print(\"Downloading Code to Colab Environment\")\n",
        "    !wget https://www.dropbox.com/sh/287dmicr7k30m3q/AADpOe7w4ouuMp2cyA1uNFjva?dl=1 -O module-code.zip -q --show-progress\n",
        "    !unzip -qq module-code.zip\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Code to Colab Environment\n",
            "module-code.zip     100%[===================>]  30.59M  30.5MB/s    in 1.0s    \n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQNgSNRJISNN"
      },
      "source": [
        "# 1. Sobel Edge Detection using filter2D()\n",
        "\n",
        "Sobel Edge Detection is one of the most widely used algorithms for edge detection. The Sobel Operator detects edges that are marked by sudden changes in pixel intensity. A sudden change in the derivative of intensity function will reveal a change in the pixel intensity as well. With this in mind, we can approximate the derivative, using a 3×3 kernel. We use one kernel to detect sudden changes in pixel intensity in the X direction, and another in the Y direction.\n",
        "\n",
        "* X-direction Kernel : $$\\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}$$\n",
        "\n",
        "* Y-direction Kernel : $$\\begin{bmatrix} 1 & 2 & 1 \\\\ 0 & 0 & 0 \\\\ -1 & -2 & -1 \\end{bmatrix}$$\n",
        "\n",
        "When these kernels are convolved with the original image, you get a ‘Sobel edge image’.\n",
        "\n",
        " * If we use only the Vertical Kernel, the convolution yields a Sobel image, with edges enhanced in the X-direction\n",
        " * Using the Horizontal Kernel yields a Sobel image, with edges enhanced in the Y-direction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgoU-0jD9o61"
      },
      "source": [
        "## 1.1 Convolution Example\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://opencv.org/wp-content/uploads/2021/09/c0-m8-02-sobel-edge-detection-a.png\" alt=\"c0-m8-02-sobel-edge-detection-a.png\">\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://opencv.org/wp-content/uploads/2021/09/c0-m8-02-sobel-edge-detection-b.png\" alt=\"c0-m8-02-sobel-edge-detection-b.png\">\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "yxIXbdaq9o64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "da672ceb-b76d-40ad-ccad-1bae02114819"
      },
      "source": [
        "image_8x8 = np.ones((8, 8), dtype = np.uint8)*90\n",
        "image_8x8[1:7,1:4] = 20\n",
        "image_8x8[1:7,4:7] = 150\n",
        "\n",
        "print(image_8x8)\n",
        "# Define the Sobel-X kernel.\n",
        "kernel = np.array([[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]])\n",
        "\n",
        "# Convolve the image with Sobel-X 3x3 kernel.\n",
        "sobelx_filter2d = cv2.filter2D(src=image_8x8, ddepth=cv2.CV_64F, kernel=kernel, borderType=cv2.BORDER_REPLICATE)\n",
        "\n",
        "\n",
        "\n",
        "# Print the filtered results (intensity gradients)\n",
        "print('')\n",
        "print(sobelx_filter2d)\n",
        "print('')\n",
        "\n",
        "# Example: Map gradients to [0, 255]\n",
        "sobelx_filter2d = sobelx_filter2d - sobelx_filter2d.min()\n",
        "sobelx_filter2d = sobelx_filter2d/sobelx_filter2d.max()\n",
        "sobelx_filter2d = (sobelx_filter2d * 255).astype('uint8')\n",
        "print(sobelx_filter2d)\n",
        "\n",
        "plt.figure(figsize = (12, 10))\n",
        "plt.subplot(121); plt.axis('off'); plt.imshow(image_8x8);       plt.title('Original Image')\n",
        "plt.subplot(122); plt.axis('off'); plt.imshow(sobelx_filter2d); plt.title('Intensity Gradients');"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 90  90  90  90  90  90  90  90]\n",
            " [ 90  20  20  20 150 150 150  90]\n",
            " [ 90  20  20  20 150 150 150  90]\n",
            " [ 90  20  20  20 150 150 150  90]\n",
            " [ 90  20  20  20 150 150 150  90]\n",
            " [ 90  20  20  20 150 150 150  90]\n",
            " [ 90  20  20  20 150 150 150  90]\n",
            " [ 90  90  90  90  90  90  90  90]]\n",
            "\n",
            "[[ -70.  -70.    0.  130.  130.    0.  -60.  -60.]\n",
            " [-210. -210.    0.  390.  390.    0. -180. -180.]\n",
            " [-280. -280.    0.  520.  520.    0. -240. -240.]\n",
            " [-280. -280.    0.  520.  520.    0. -240. -240.]\n",
            " [-280. -280.    0.  520.  520.    0. -240. -240.]\n",
            " [-280. -280.    0.  520.  520.    0. -240. -240.]\n",
            " [-210. -210.    0.  390.  390.    0. -180. -180.]\n",
            " [ -70.  -70.    0.  130.  130.    0.  -60.  -60.]]\n",
            "\n",
            "[[ 66  66  89 130 130  89  70  70]\n",
            " [ 22  22  89 213 213  89  31  31]\n",
            " [  0   0  89 255 255  89  12  12]\n",
            " [  0   0  89 255 255  89  12  12]\n",
            " [  0   0  89 255 255  89  12  12]\n",
            " [  0   0  89 255 255  89  12  12]\n",
            " [ 22  22  89 213 213  89  31  31]\n",
            " [ 66  66  89 130 130  89  70  70]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHRCAYAAABelCVTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIK5JREFUeJzt3X2UVIV5+PFnWZBFEBRYBLVREItBbAWsoSoQiQlNQIEQE4EQQIMmVhTqG00kgInIQjbBUInGWDDgW1GhGqrEKlapsY3J8Q1tIka0sb7CoiiIkZ3fH57dn8PysiJmeMLnc47nyN07c5+7o9z5zp07U1YoFAoBAAAASTUp9QAAAADwUQhbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJW/7sTJs2LcrKynbptgsWLIiysrJYs2bN7h3qA9asWRNlZWWxYMGCj20bAEBDZWVlMW3atFKP8Se39X7/KZ7vwJ+asGWPsWrVqvjqV78aBx98cDRv3jwOOuigGDVqVKxatarUo5XE/fffH2VlZXHrrbeWehQA9lJ1AfTII4986Ntu3Lgxpk2bFvfff//uH2w3eeihh2LatGmxfv36j+X+77zzzjjllFPiwAMPjH322Sfatm0b/fr1i+rq6njzzTc/lm3uKTI8/vx5EbbsEW6//fbo1atX3HvvvTFu3LiYN29enHnmmbFixYro1atXLFmypNH3demll8amTZt2aY7Ro0fHpk2b4tBDD92l2wMA79u4cWNMnz59jwqbTZs2xaWXXlr/54ceeiimT5++28O2trY2xo0bF6eeemo8//zzcc4558TVV18dU6dOjYMOOiguvfTSGDZs2G7d5ofxp3i+syc+/vx5a1rqAeDZZ5+N0aNHR5cuXeKBBx6IysrK+p+df/750bdv3xg9enQ8/vjj0aVLl+3ez9tvvx0tW7aMpk2bRtOmu/afdnl5eZSXl+/SbQGAPVtFRcWfZDuzZs2KBQsWxKRJk6K6urroEqnzzz8/XnrppfjZz362w/uora2Nd99992OZ2fMd/hw5Y0vJzZ49OzZu3Bg/+clPiqI2IqJ9+/ZxzTXXxNtvvx2zZs2qX153He1TTz0VI0eOjAMOOCBOPPHEop990KZNm+K8886L9u3bx3777RennnpqvPjii4265uSwww6LwYMHx8qVK+O4446LioqK6NKlS4MD0rp16+LCCy+Mo48+Olq1ahWtW7eOz3/+8/HYY4/tpt/U/9+33/3ud/HVr3412rRpE5WVlTFlypQoFArxv//7vzFkyJBo3bp1dOzYMaqrq4tu/+6778Z3vvOd6N27d7Rp0yZatmwZffv2jRUrVjTY1tq1a2P06NHRunXr2H///WPMmDHx2GOPbfP64P/5n/+JL33pS9G2bduoqKiIY489Nu64447dtt8A7DnGjh0brVq1ihdffDGGDh0arVq1isrKyrjwwgtjy5YtEfH+50nUHdOnT58eZWVlDY65jTl21B2X//M//zP+4R/+ISorK6Nly5YxbNiweO2114rWfeSRR2LgwIHRvn37aNGiRXTu3DnOOOOMonU+OMO0adPioosuioiIzp0718+4Zs2a6N+/f/z1X//1Nve/W7duMXDgwO3+fjZu3BhVVVVx1FFHxezZs7f5uR+dOnWKSy65pMFs5557btxwww1x1FFHRfPmzePuu++OiIjvf//7cfzxx0e7du2iRYsW0bt3721eqrR58+aYNGlSVFZW1j/f+cMf/tBgve1dY3vXXXdF3759o2XLlrHffvvFoEGDGlwStjse/5dffjnGjRsXhxxySDRv3jw6deoUQ4YMcc0vH4mwpeTuvPPOOOyww6Jv377b/Hm/fv3isMMOi2XLljX42WmnnRYbN26MGTNmxPjx47e7jbFjx8bcuXPjC1/4QlRVVUWLFi1i0KBBjZ5x9erV8aUvfSk++9nPRnV1dRxwwAExduzYor/sf//738fSpUtj8ODB8YMf/CAuuuiieOKJJ6J///7xf//3f43eVmN85Stfidra2pg5c2Z86lOfiu9973sxZ86c+OxnPxsHH3xwVFVVRdeuXePCCy+MBx54oP52b775Zvz0pz+NT3/601FVVRXTpk2L1157LQYOHBiPPvpo/Xq1tbVxyimnxE033RRjxoyJyy+/PF566aUYM2ZMg1lWrVoVffr0iaeffjomT54c1dXV0bJlyxg6dOiHegs5AHls2bIlBg4cGO3atYvvf//70b9//6iuro6f/OQnERFRWVkZP/7xjyMiYtiwYbFw4cJYuHBhfPGLX4yID3/smDBhQjz22GMxderU+OY3vxl33nlnnHvuufU/f/XVV+Nzn/tcrFmzJiZPnhxz586NUaNGxcMPP7zdffjiF78YI0aMiIiIH/7wh/UzVlZW1r9T7Mknnyy6za9+9av6F5e3Z+XKlbF+/foYMWLEhz4ret9998WkSZPiK1/5Slx55ZVx2GGHRUTElVdeGT179ozLLrssZsyYEU2bNo3TTjutwXOjr3/96zFnzpz43Oc+FzNnzoxmzZo1+vnOwoULY9CgQdGqVauoqqqKKVOmxFNPPRUnnnhig+D8qI//8OHDY8mSJfWXn5133nmxYcOGeOGFFz7U7wuKFKCE1q9fX4iIwpAhQ3a43qmnnlqIiMKbb75ZKBQKhalTpxYiojBixIgG69b9rM6vf/3rQkQUJk6cWLTe2LFjCxFRmDp1av2y+fPnFyKi8Nxzz9UvO/TQQwsRUXjggQfql7366quF5s2bFy644IL6Ze+8805hy5YtRdt47rnnCs2bNy9cdtllRcsiojB//vwd7vOKFSsKEVFYvHhxg30766yz6pe99957hUMOOaRQVlZWmDlzZv3ympqaQosWLQpjxowpWnfz5s1F26mpqSkceOCBhTPOOKN+2W233VaIiMKcOXPql23ZsqUwYMCABrN/5jOfKRx99NGFd955p35ZbW1t4fjjjy8cccQRO9xHAPZsdcfFX/3qV/XLxowZU4iIomNboVAo9OzZs9C7d+/6P7/22msNjrN1GnvsqNv+ySefXKitra1fPmnSpEJ5eXlh/fr1hUKhUFiyZEmDObdl63lmz57d4LhfKLz//KSioqJwySWXFC0/77zzCi1btiy89dZb293GlVdeWYiIwtKlS4uWv/fee4XXXnut6J8P7lNEFJo0aVJYtWpVg/vcuHFj0Z/ffffdQo8ePQoDBgyoX/boo48WIqJwzjnnFK07cuTInT7f2bBhQ2H//fcvjB8/vui2L7/8cqFNmzZFyz/q419TU1OIiMLs2bMb7Cd8FM7YUlIbNmyIiIj99ttvh+vV/XzrTxD8xje+sdNt1L2N55xzzilaPmHChEbP2b1796IzypWVldGtW7f4/e9/X7+sefPm0aTJ+/9LbdmyJdauXRutWrWKbt26xW9+85tGb6sxvv71r9f/e3l5eRx77LFRKBTizDPPrF++//77N5ixvLw89tlnn4h4/6zsunXr4r333otjjz22aMa77747mjVrVnQWvEmTJvH3f//3RXOsW7cu7rvvvvjyl78cGzZsiNdffz1ef/31WLt2bQwcODCeeeaZePHFF3frvgOwZ9j6GNy3b9+iY8727Mqx46yzzip6S2/fvn1jy5Yt8fzzz0fE+8e8iIif//zn8cc//vEj7llEmzZtYsiQIXHTTTdFoVCIiPeP7bfccksMHTo0WrZsud3b1j1XadWqVdHyJ554IiorK4v+Wbt2bdE6/fv3j+7duze4zxYtWtT/e01NTbzxxhvRt2/fomP3v/3bv0VExHnnnVd024kTJ+50f++55576s8x1j8frr78e5eXl8alPfWqblyzt6uPfokWL2GeffeL++++Pmpqana4PjSVsKam6YK0L3O3ZXgB37tx5p9t4/vnno0mTJg3W7dq1a6Pn/MQnPtFg2QEHHFD0F3JtbW388Ic/jCOOOCKaN28e7du3j8rKynj88cfjjTfeaPS2dmWeNm3aREVFRbRv377B8q0PGtdff3381V/9VVRUVES7du2isrIyli1bVjTj888/H506dYp999236LZb/85Wr14dhUIhpkyZ0uBgPXXq1Ih4/+1hAPx5qaioaPC5GFsfF7dnV44dWx/3DjjggIiI+u31798/hg8fHtOnT4/27dvHkCFDYv78+bF58+Zd3sevfe1r8cILL8SDDz4YERH//u//Hq+88kqMHj16h7ere67y1ltvFS3v2rVr3HPPPXHPPfds9z6297zm5z//efTp0ycqKiqibdu29W/13frY3aRJkzj88MOLbtutW7cd72hEPPPMMxERMWDAgAaPyS9+8YsGj8dHefybN28eVVVVcdddd8WBBx4Y/fr1i1mzZsXLL7+809vCjvhUZEqqTZs20alTp3j88cd3uN7jjz8eBx98cLRu3bpo+Qdfwfw4be8ambpXcSMiZsyYEVOmTIkzzjgjvvvd70bbtm2jSZMmMXHixKitrf3Y52nMjIsWLYqxY8fG0KFD46KLLooOHTpEeXl5XHHFFfHss89+6Dnq9uvCCy/c7gdpfJgXEADI4aN8ou6uHDt2doyr+973hx9+OO68885Yvnx5nHHGGVFdXR0PP/xwg7OnjTFw4MA48MADY9GiRdGvX79YtGhRdOzYMU4++eQd3u7II4+MiIgnn3wyhgwZUr+8VatW9bdduXLlNm+7rec1Dz74YJx66qnRr1+/mDdvXnTq1CmaNWsW8+fPjxtvvPFD79e21D0mCxcujI4dOzb4+dbfNvFRP1F54sSJccopp8TSpUtj+fLlMWXKlLjiiivivvvui549e36k+2bvJWwpucGDB8e1114bK1eurP9k4w968MEHY82aNXH22Wfv0v0feuihUVtbG88991wcccQR9ctXr169yzNvy6233honnXRSXHfddUXL169f3+BMaqnceuut0aVLl7j99tuL3tJV9wp5nUMPPTRWrFgRGzduLDpru/XvrO7rl5o1a7bTAz0Ae5dtfRpwxMd77OjTp0/06dMnLr/88rjxxhtj1KhRcfPNNxddwtOYGSPej7eRI0fGggULoqqqKpYuXRrjx4/fadT17ds32rRpEzfffHP84z/+Y/1lSrvqtttui4qKili+fHk0b968fvn8+fOL1qt7vvPss88WnaX97W9/u9Nt1J3l7dChw257THb0u63b5gUXXBAXXHBBPPPMM3HMMcdEdXV1LFq0aLdsn72PtyJTchdddFG0aNEizj777AbXmqxbty6+8Y1vxL777lv/kfwfVt2rwfPmzStaPnfu3F0beDvKy8uLzo5GRCxevHiPusa07mD8wTn/67/+K375y18WrTdw4MD44x//GNdee239stra2rjqqquK1uvQoUN8+tOfjmuuuSZeeumlBtvb+qsYANh71L0wun79+qLlH8exo6ampsEx+JhjjomI2OHbkeuuld16xjqjR4+OmpqaOPvss+Ott97a4ach19l3333j4osvjieffDImT57cYK6I2Oay7SkvL4+ysrL6r9KJeP/rdJYuXVq03uc///mIiPjRj35UtHzOnDk73cbAgQOjdevWMWPGjG1eo7wrj8n2Hv+NGzfGO++8U7Ts8MMPj/322+8jvXUcnLGl5I444oi4/vrrY9SoUXH00UfHmWeeGZ07d441a9bEddddF6+//nrcdNNNDa4ZaazevXvH8OHDY86cObF27dro06dP/Md//Ef87ne/i4idv6LYWIMHD47LLrssxo0bF8cff3w88cQTccMNN9S/Mr0nGDx4cNx+++0xbNiwGDRoUDz33HNx9dVXR/fu3YuuBRo6dGgcd9xxccEFF8Tq1avjyCOPjDvuuCPWrVsXEcW/s6uuuipOPPHEOProo2P8+PHRpUuXeOWVV+KXv/xl/OEPf9it3+MLQB4tWrSI7t27xy233BJ/+Zd/GW3bto0ePXpEjx49dvux4/rrr4958+bFsGHD4vDDD48NGzbEtddeG61bt44vfOEL271d7969IyLi29/+dpx++unRrFmzOOWUU+qDt2fPntGjR49YvHhxfPKTn4xevXo1ap7JkyfH008/HbNnz45f/OIXMXz48DjkkEOipqYmfvOb38TixYujQ4cOUVFRsdP7GjRoUPzgBz+Iv/u7v4uRI0fGq6++GldddVV07dq16FKuY445JkaMGBHz5s2LN954I44//vi49957G/UOtdatW8ePf/zjGD16dPTq1StOP/30qKysjBdeeCGWLVsWJ5xwQvzTP/1To/a9zvYe//feey8+85nPxJe//OXo3r17NG3aNJYsWRKvvPJKnH766R9qG/BBwpY9wmmnnRZHHnlkXHHFFfUx265duzjppJPiW9/6VvTo0eMj3f/Pfvaz6NixY9x0002xZMmSOPnkk+OWW26Jbt26Neqg0hjf+ta34u23344bb7wxbrnllujVq1csW7YsJk+evFvuf3cYO3ZsvPzyy3HNNdfE8uXLo3v37rFo0aJYvHhx3H///fXrlZeXx7Jly+L888+P66+/Ppo0aRLDhg2LqVOnxgknnFD0O+vevXs88sgjMX369FiwYEGsXbs2OnToED179ozvfOc7JdhLAPYUP/3pT2PChAkxadKkePfdd2Pq1KnRo0eP3X7s6N+/f/z3f/933HzzzfHKK69EmzZt4rjjjosbbrhhhx80+Td/8zfx3e9+N66++uq4++676y9d+uCnHn/ta1+Liy++eKcfGvVBTZo0iYULF8bw4cPj2muvjblz50ZNTU20atUqevToEZdffnmMHz++Udf+DhgwIK677rqYOXNmTJw4MTp37hxVVVWxZs2aBp9R8s///M9RWVkZN9xwQyxdujQGDBgQy5Yti7/4i7/Y6XZGjhwZBx10UMycOTNmz54dmzdvjoMPPjj69u0b48aNa/S+f9C2Hv8JEybEiBEj4t57742FCxdG06ZN48gjj4x/+Zd/ieHDh+/SdiAioqzwYd4LAX9GHn300ejZs2csWrQoRo0aVepxUli6dGkMGzYsVq5cGSeccEKpxwGAj92VV14ZkyZNijVr1mzzWxKAPYNrbNkrbNq0qcGyOXPmRJMmTaJfv34lmGjPt/XvbMuWLTF37txo3bp1o9+KBQCZFQqFuO6666J///6iFvZw3orMXmHWrFnx61//Ok466aRo2rRp3HXXXXHXXXfFWWed1ai35+yNJkyYEJs2bYq//du/jc2bN8ftt98eDz30UMyYMeNP9jVLAFAKb7/9dtxxxx2xYsWKeOKJJ+Jf//VfSz0SsBPeisxe4Z577onp06fHU089FW+99VZ84hOfiNGjR8e3v/3tBt/NxvtuvPHGqK6ujtWrV8c777wTXbt2jW9+85tx7rnnlno0APhYrVmzJjp37hz7779/nHPOOXH55ZeXeiRgJ4QtAAAAqbnGFgAAgNSELQAAAKkJWwAAAFJr9KfmzJo16+OcAwA+tIsvvrjUI/xZGTBgQKlHoBE6duxY6hF2u09+8pOlHoGdePrpp0s9wm63du3aUo9AIyxfvrxR6zljCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFJrWuoBSumSSy4p9QjshQqFQqlHYC81a9asUo/AHm7VqlWlHoFG6NixY6lH2O2GDx9e6hHYie9973ulHmG3++1vf1vqEdiNnLEFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqTUt9QAAwJ7h1VdfLfUI7KW6d+9e6hHYC61du7bUI7AbOWMLAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUmpZ6AABgz9ChQ4dSj8Be6qmnnir1COyF2rVrV+oR2I2csQUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpNS31AKVUVVVV6hHYC82aNavUIwBs01FHHVXqEdhL3XbbbaUegb1Qt27dSj0Cu5EztgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACA1YQsAAEBqwhYAAIDUhC0AAACpCVsAAABSE7YAAACkJmwBAABITdgCAACQmrAFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAIDVhCwAAQGrCFgAAgNSELQAAAKkJWwAAAFITtgAAAKQmbAEAAEhN2AIAAJCasAUAACC1skKhUCj1EAAAALCrnLEFAAAgNWELAABAasIWAACA1IQtAAAAqQlbAAAAUhO2AAAApCZsAQAASE3YAgAAkJqwBQAAILX/Bw0cve+qPPHZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W71t6pZl9o6-"
      },
      "source": [
        "## 1.2 Detect Vertical Edges using Sobel-X Kernel and filter2D()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5K7q_v59o6_"
      },
      "source": [
        "### <font style = \"color:rgb(50,120,229)\">Convert to grayscale</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNNRKX0z9o7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2b66aa-cd96-4e38-b253-fc8f1737c1bf"
      },
      "source": [
        "# Read image.\n",
        "img = cv2.imread('checkerboard_color.png')\n",
        "# Convert to grayscale.\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "print(img.shape)\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.subplot(121); plt.axis('off'); plt.imshow(img[:,:,::-1]); plt.title('Original')\n",
        "plt.subplot(122); plt.axis('off'); plt.imshow(img_gray);      plt.title('Gray Scale');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 800, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10xdey7X9o7B"
      },
      "source": [
        "### <font style = \"color:rgb(50,120,229)\">Define a Kernel and Apply Convolution</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1-nuiPj9o7C"
      },
      "source": [
        "# Define a Sobel-X kernel.\n",
        "kernel = np.array([[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]])\n",
        "\n",
        "sobelx = cv2.filter2D(src = img_gray, ddepth = cv2.CV_64F, kernel = kernel)\n",
        "\n",
        "plt.figure(figsize = (20,12))\n",
        "plt.subplot(131); plt.axis('off'); plt.imshow(img[:,:,::-1]); plt.title('Original')\n",
        "plt.subplot(132); plt.axis('off'); plt.imshow(img_gray);      plt.title('Grayscale')\n",
        "plt.subplot(133); plt.axis('off'); plt.imshow(sobelx);        plt.title('Sobel-X Edge Map');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSNSsUCr9o7D"
      },
      "source": [
        "# 2. Using Sobel() to Detect Vertical and Horizontal Edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncs33HKN9o7E"
      },
      "source": [
        "OpenCV has a dedicated function called `Sobel()` that performs Sobel edge detection which is more conveninet that using the more general `filer2D()` function. Let's see how to use `Sobel()`.\n",
        "\n",
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
        "\n",
        "### <font style = \"color:rgb(8,133,37)\">Function Syntax</font>\n",
        "\n",
        "```python\n",
        "dst = cv.Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]])\n",
        "```\n",
        "\n",
        "`dst`: output image of the same size and the same number of channels as src .\n",
        "\n",
        "The function has **4 required arguments**:\n",
        "\n",
        " 1. `src`: input image.\n",
        " 2. `ddepth`: is the depth of the destination image.\n",
        " 3.  `dx`: Horizontal sobel derivative.\n",
        " 4.  `dy`: Vertical sobel derivative.\n",
        "\n",
        "\n",
        "### <font style=\"color:rgb(8,133,37)\">OpenCV Documentation</font>\n",
        "\n",
        "[**`sobel()`**](https://docs.opencv.org/4.5.2/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d)\n",
        "\n",
        " <hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syTf0e659o7F"
      },
      "source": [
        "## 2.1 Using Sobel() to Detect Vertical and Horizontal Edges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muI754tgKM1F"
      },
      "source": [
        "sobelx  = cv2.Sobel(src = img_gray, ddepth = cv2.CV_64F, dx = 1, dy = 0, ksize = 3)\n",
        "sobely  = cv2.Sobel(src = img_gray, ddepth = cv2.CV_64F, dx = 0, dy = 1, ksize = 3)\n",
        "\n",
        "plt.figure(figsize = (20,12))\n",
        "plt.subplot(141); plt.axis('off'); plt.imshow(img[:,:,::-1]); plt.title('Original')\n",
        "plt.subplot(142); plt.axis('off'); plt.imshow(img_gray);      plt.title('Grayscale')\n",
        "plt.subplot(143); plt.axis('off'); plt.imshow(sobelx);        plt.title('Sobel-X Edge Map')\n",
        "plt.subplot(144); plt.axis('off'); plt.imshow(sobely);        plt.title('Sobel-Y Edge Map');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2_1YCT3Q5d8"
      },
      "source": [
        "# 3. Canny Edge Detection\n",
        "\n",
        "Canny Edge Detection is one of the most popular edge-detection methods in use today because it is so robust and flexible. The algorithm itself follows a three-stage process for extracting edges from an image. Blurring is almost always added as a pre-processing step to reduce noise. This makes it a four-stage process, which includes:\n",
        "\n",
        " 0. Pre-processing step: Noise Reduction (blurring)\n",
        " 1. Calculating the intensity gradient of the image (using a Sobel kernel)\n",
        " 2. Non-maximum Suppression\n",
        " 3. Hysteresis thresholding\n",
        "\n",
        " <hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
        "\n",
        "### <font style = \"color:rgb(8,133,37)\">Function Syntax</font>\n",
        "\n",
        "```python\n",
        "edges = cv.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]])\n",
        "```\n",
        "\n",
        " `edges`:\toutput edge map; single channels 8-bit image, which has the same size as image .\n",
        "\n",
        "The function has **3 required arguments**:\n",
        "\n",
        "1. `src` : Input image.\n",
        "2. `threshold1`: First threshold for the hysteresis procedure.\n",
        "3. `threshold2`: Second threshold for the hysteresis procedure.\n",
        "\n",
        "**NOTE**: The thresholds described above are interchangeable as arguments in the function call. The higher of the two values specified corresponds to the threshold for determining which edges are \"Sure Edges\" and the lower of the two thresholds is used for determining which edges qualify as candidate edges (if they are determined to be connected to a \"Sure Edge\"). What this means is that the order of these two arguments does not matter. In this notebook we will simply refer to `thresold1` as the lower threshold and `threshold2` as the upper (or higher) threshold.\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://opencv.org/wp-content/uploads/2021/09/c0-m8-02-canny-thresholds.png\" alt=\"c0-m8-02-canny-thresholds.png\">\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Edges with intensity gradients greater than the high threshold are considered \"Sure Edges.\" Edges with intensity gardients less than the high threshold, but greater than the low threshold are considered candidate edges. If the candidate edges are connected to a \"Sure Edge\" then they become a valid edge and are included in the final edge map. All other edges whose intensity gradients are less than the high threshold value are discarded.\n",
        "\n",
        "### <font style=\"color:rgb(8,133,37)\">OpenCV Documentation</font>\n",
        "\n",
        "[**`Canny()`**](https://docs.opencv.org/4.5.2/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de)\n",
        "\n",
        "[**`Canny Edge Detection Tutorial`**](https://docs.opencv.org/4.5.2/da/d22/tutorial_py_canny.html)\n",
        "\n",
        " <hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Fop9Bc9o7J"
      },
      "source": [
        "## 3.1 Canny Edge Detection (simple example with no texture or noise)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVZjj7haD4dY"
      },
      "source": [
        "img = cv2.imread('coca-cola-logo.png')\n",
        "\n",
        "# Convert to grayscale.\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "edges = cv2.Canny(img_gray, threshold1 = 180, threshold2 = 200)\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.subplot(131); plt.axis(\"off\"); plt.imshow(img[:,:,::-1]); plt.title('Original')\n",
        "plt.subplot(132); plt.axis(\"off\"); plt.imshow(img_gray);      plt.title('Grayscale')\n",
        "plt.subplot(133); plt.axis(\"off\"); plt.imshow(edges);         plt.title('Canny Edge Map');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7J5GwKz9o7M"
      },
      "source": [
        "## 3.2 Effect of Threshold2\n",
        "\n",
        "The upper threshold (`Threshold2`) determines which edges will be included in the final edge map as \"sure-edges\" (i.e., those edges whoes intensity gradients exceed the value of `Threshold2`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_LmVfaa9o7M"
      },
      "source": [
        "img = cv2.imread('phone_ipad.jpg')\n",
        "\n",
        "# Convert to grayscale.\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "edges1 = cv2.Canny(img_gray, threshold1 = 200, threshold2 = 300)\n",
        "edges2 = cv2.Canny(img_gray, threshold1 = 200, threshold2 = 500)\n",
        "edges3 = cv2.Canny(img_gray, threshold1 = 200, threshold2 = 1000)\n",
        "\n",
        "plt.figure(figsize = (20,12))\n",
        "plt.subplot(221); plt.axis(\"off\"); plt.imshow(img_gray);  plt.title('Grayscale')\n",
        "plt.subplot(222); plt.axis(\"off\"); plt.imshow(edges1);    plt.title('Edges with T2 = 300')\n",
        "plt.subplot(223); plt.axis(\"off\"); plt.imshow(edges2);    plt.title('Edges with T2 = 500')\n",
        "plt.subplot(224); plt.axis(\"off\"); plt.imshow(edges3);    plt.title('Edges with T2 = 1000');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A3a3FEJ9o7O"
      },
      "source": [
        "# 4.  Canny Edge Detection (with and without blurring)\n",
        "This section shows the application of image blurring prior to performing edge detection. We will compare edge detection results with and without blurring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W33mC9889o7P"
      },
      "source": [
        "# Read image.\n",
        "img1 = cv2.imread('butterfly.jpg')\n",
        "img2 = cv2.imread('Large_Scaled_Forest_Lizard.jpg')\n",
        "\n",
        "# Convert to gray scale.\n",
        "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJLuv8_9o7P"
      },
      "source": [
        "## 4.1  Canny Edge Detection without Blurring\n",
        "\n",
        "When edge detection is performed on the original image (without any blurring) the algorithm often produces many edges associated with the texture in the image which are not necessarily associated with the edges we often care about."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9poVD129o7Q"
      },
      "source": [
        "# Canny Edge detection without blurring.\n",
        "original_edges_1 = cv2.Canny(img1_gray, threshold1 = 180, threshold2 = 200)\n",
        "original_edges_2 = cv2.Canny(img2_gray, threshold1 = 180, threshold2 = 200)\n",
        "\n",
        "# Display.\n",
        "plt.figure(figsize = (20,15))\n",
        "plt.subplot(221); plt.axis('off'); plt.imshow(img1[:,:,::-1]);   plt.title('Original')\n",
        "plt.subplot(222); plt.axis('off'); plt.imshow(original_edges_1); plt.title('Edges from original')\n",
        "\n",
        "plt.subplot(223); plt.axis('off'); plt.imshow(img2[:,:,::-1]);   plt.title('Original')\n",
        "plt.subplot(224); plt.axis('off'); plt.imshow(original_edges_2); plt.title('Edges from original');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0an-Dfd9o7Q"
      },
      "source": [
        "## 4.2  Canny Edge Detection with Blurring\n",
        "\n",
        "We apply blurring to smooth out the fine texture and reduce noise in images so that only the predominant edges are detected in the image.\n",
        "\n",
        "### <font style = \"color:rgb(50,120,229)\">Apply blurring</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "W-ZDpoxZ9o7R"
      },
      "source": [
        "# Apply Gaussian blur with kernel size 7x7.\n",
        "img1_blur = cv2.GaussianBlur(img1_gray, (7,7), 0)\n",
        "# Apply Gaussian blur with kernel size 7x7 as the noise is more.\n",
        "img2_blur = cv2.GaussianBlur(img2_gray, (7,7), 0)\n",
        "\n",
        "# Display the images.\n",
        "plt.figure(figsize = (20, 10))\n",
        "plt.subplot(231); plt.axis('off'); plt.imshow(img1[:,:,::-1]); plt.title('Original')\n",
        "plt.subplot(232); plt.axis('off'); plt.imshow(img1_gray);      plt.title('Grayscale')\n",
        "plt.subplot(233); plt.axis('off'); plt.imshow(img1_blur);      plt.title('Blurred')\n",
        "plt.subplot(234); plt.axis('off'); plt.imshow(img2[:,:,::-1]); plt.title('Original')\n",
        "plt.subplot(235); plt.axis('off'); plt.imshow(img2_gray);      plt.title('Grayscale')\n",
        "plt.subplot(236); plt.axis('off'); plt.imshow(img2_blur);      plt.title('Blurred');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvFsqiP-9o7R"
      },
      "source": [
        "### <font style = \"color:rgb(50,120,229)\">Perform edge detection using blurred images</font>\n",
        "\n",
        "Using the blurred image as input eliminates edges associated with very fine texture or noise in the original image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp03wm7F9o7R"
      },
      "source": [
        "blurred_edges_1 = cv2.Canny(img1_blur, threshold1 = 180, threshold2 = 200)\n",
        "blurred_edges_2 = cv2.Canny(img2_blur, threshold1 = 180, threshold2 = 200)\n",
        "\n",
        "# Display.\n",
        "plt.figure(figsize = (18,12))\n",
        "plt.subplot(221); plt.axis('off'); plt.imshow(original_edges_1); plt.title('Edges without blur')\n",
        "plt.subplot(222); plt.axis('off'); plt.imshow(blurred_edges_1);  plt.title('Edges with blur')\n",
        "plt.subplot(223); plt.axis('off'); plt.imshow(original_edges_2); plt.title('Edges without blur')\n",
        "plt.subplot(224); plt.axis('off'); plt.imshow(blurred_edges_2);  plt.title('Edges with blur');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkwgLdFe9o7S"
      },
      "source": [
        "## 4.3 Hysteresis Thresholding Example (effect of Threshold1)\n",
        "Setting a lower minimum threshold (`threshold1`) allows weaker edges to be included in the final edge map as long as the weaker edge can be associated with a \"sure-edge.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9kwIrixw9o7T"
      },
      "source": [
        "# Edge detection with a high Threshold1 value.\n",
        "blurred_edges_tight = cv2.Canny(img1_blur, threshold1 = 180, threshold2 = 200)\n",
        "# Edge detection with a low Threshold1 value.\n",
        "blurred_edges_open  = cv2.Canny(img1_blur, threshold1 = 50, threshold2 = 200)\n",
        "\n",
        "plt.figure(figsize = (20,15))\n",
        "plt.subplot(121); plt.axis('off'); plt.imshow(blurred_edges_tight); plt.title('Threshold1 = 180, Threshold2 = 200')\n",
        "plt.subplot(122); plt.axis('off'); plt.imshow(blurred_edges_open);  plt.title('Threshold1 = 50, Threshold2 = 200');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFQx3fjN9o7T"
      },
      "source": [
        "As shown in the images above, the edge map associated with a higher Threshold1 value (left) has many \"broken edges.\" When the Threshold1 value is lowered it allows weaker segments that are assocaited with strong edges to become part of the final edge map as shown to the right. In the right-hand image, you can see more continuous edges."
      ]
    }
  ]
}